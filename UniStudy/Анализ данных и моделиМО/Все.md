	1. Общий подход к сбору данных для машинного обучения. Важность и методы предварительной обработки данных.
	2. Разделение выборок на тренировочную и тестовую. Основные принципы и подходы.
	3. Постановка задач классификации и регрессии. Основной принцип построения модели.
	4. Переобучение и недообучение модели. K-fold cross validation. Процедура построения и зачем это необходимо.
	5. Метрики для задачи регрессии. MAE, SSR, MSE, RMSE, R^2. Определения, преимущества и недостатки.
	6. Линейная регрессия. Определение одномерной и многомерной модели для задач регрессии и классификации.
	7. P-value. Значение и применение в контексте оценки моделей.
	8. Процедура градиентного спуска. Пример работы на линейной регрессии. Стохастический градиентный спуск.
	9. Логистическая регрессия. Определение, процедура обучения, связь с линейной регрессией. Проблема underflow для log(likelihood).
	10. Метрики для задачи классификации. Accuracy, Матрица ошибок, precision, recall, F-measure. Определения, преимущества и недостатки.
	11. AUC ROC для оценки качества полученной модели.
	12. Методы отбора признаков (feature selection). Основные подходы и их применение.
	13. Проблема мультиколлинеарности в линейной регрессии. Способы выявления и решения.
	14. Ансамблевые методы. Введение в случайные леса (Random Forest).
	15. Оценка важности признаков. Методы и их использование в интерпретации моделей.